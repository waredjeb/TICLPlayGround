{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbbc77-ba10-4807-abc6-1aedd79156ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If files have been already dumped in parquet format\n",
    "import uproot, numpy as np, awkward as ak\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import awkward as ak\n",
    "import os, pathlib\n",
    "from pathlib import Path\n",
    "import ROOT\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import *\n",
    "\n",
    "parq_dir = Path(\"parquet_out\")\n",
    "\n",
    "# pick just the trees you need\n",
    "need = [\n",
    "    \"ticlTrackstersCLUE3DHigh\",\n",
    "    \"ticlCandidate\",\n",
    "    \"simtrackstersCP\",\n",
    "    \"associations\",\n",
    "]\n",
    "\n",
    "dump_data = {name: ak.from_parquet(parq_dir / f\"{name}.parquet\")\n",
    "             for name in need}\n",
    "\n",
    "# ── usage ────────────────────────────────────────────────────────────────\n",
    "ticlTrackstersCLUE3D = dump_data[\"ticlTrackstersCLUE3DHigh\"]\n",
    "ticlCandidate = dump_data[\"ticlCandidate\"]\n",
    "simTrackstersCP = dump_data[\"simtrackstersCP\"] \n",
    "associations = dump_data[\"associations\"]\n",
    "assert len(associations) == len(simTrackstersCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c901a7-68b9-4551-a3cd-633ded208712",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c3d9e1-9a91-41ae-bfaa-e7e6be1f1f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:34<00:00, 29.26it/s]\n"
     ]
    }
   ],
   "source": [
    "sim_to_reco_tables = []\n",
    "reco_to_sim_tables = []\n",
    "all_merged_reco    = []\n",
    "Nevents = 1000\n",
    "for ev in tqdm(range(Nevents)):\n",
    "    reco_ev = ticlCandidate[ev]\n",
    "    sim_ev  = simTrackstersCP[ev]\n",
    "\n",
    "    # no Trackster objects: just dict views\n",
    "    merged_reco = event_to_views(reco_ev)\n",
    "    all_merged_reco.append(merged_reco)\n",
    "\n",
    "    if len(sim_ev.raw_energy) == 0:\n",
    "        sim_to_reco_tables.append([])\n",
    "        reco_to_sim_tables.append([])\n",
    "        continue\n",
    "\n",
    "    sim_to_reco_tables.append(\n",
    "        compute_sim_to_reco_scores(sim_ev, merged_reco, best_only=True)\n",
    "    )\n",
    "    reco_to_sim_tables.append(\n",
    "        compute_reco_to_sim_scores(sim_ev, merged_reco, best_only=False)\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80020c-6ef5-414b-941a-237a23186f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_efficiency = aggregate_for_efficiency(simTrackstersCP, sim_to_reco_tables,\n",
    "                           score_threshold=0.5)\n",
    "data_merged = aggregate_for_merge(all_merged_reco, reco_to_sim_tables,\n",
    "                           score_threshold=0.6)\n",
    "data_fake = aggregate_for_fake(all_merged_reco, reco_to_sim_tables,\n",
    "                           score_threshold=0.6)\n",
    "plot_all_metrics(\n",
    "    data_efficiency,\n",
    "    data_merged,\n",
    "    data_fake,\n",
    "    out_file=\"ticl_metrics_baseline.pdf\"   # omit if you don’t need a file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960915c-649e-4795-b61b-d39f437604dd",
   "metadata": {},
   "source": [
    "# New Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87308fc-0bef-46e4-a6b5-46ca60e45941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, functools\n",
    "import numpy as np\n",
    "\n",
    "#To use for merging Tracksters together\n",
    "def merge_views(a: dict, b: dict) -> dict:\n",
    "    \"\"\"Return a NEW dict that is the energy-weighted merge of a & b.\"\"\"\n",
    "    Ea, Eb = a[\"raw_energy\"], b[\"raw_energy\"]\n",
    "    Etot   = Ea + Eb if (Ea + Eb) else 1.0          # avoid /0\n",
    "\n",
    "    # energy-weighted barycentres\n",
    "    bx = (a[\"barycenter_eta\"] * Ea + b[\"barycenter_eta\"] * Eb) / Etot\n",
    "    by = (a[\"barycenter_phi\"] * Ea + b[\"barycenter_phi\"] * Eb) / Etot\n",
    "\n",
    "    # concatenate LC arrays\n",
    "    v_idx = a[\"vertices_indexes\"] + b[\"vertices_indexes\"]\n",
    "    v_E   = a[\"vertices_energy\"]  + b[\"vertices_energy\"]\n",
    "    v_mul = a[\"vertices_multiplicity\"] + b[\"vertices_multiplicity\"]\n",
    "\n",
    "    merged = dict(a)              # shallow copy of first view\n",
    "    merged.update(\n",
    "        raw_energy=Etot,\n",
    "        regressed_pt=a.get(\"regressed_pt\", np.nan) +      # placeholder logic\n",
    "                     b.get(\"regressed_pt\", np.nan),\n",
    "        barycenter_eta=bx,\n",
    "        barycenter_phi=by,\n",
    "        vertices_indexes=v_idx,\n",
    "        vertices_energy=v_E,\n",
    "        vertices_multiplicity=v_mul,\n",
    "    )\n",
    "    return merged\n",
    "\n",
    "#Your algo\n",
    "def random_group_merging(event_rec, *, max_group_size=3, rng=None):\n",
    "    \"\"\"\n",
    "    Returns list[dict] of possibly-merged Reco tracksters for one event.\n",
    "    Works entirely with dict views => no deepcopy cost.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = random\n",
    "    n = len(event_rec.raw_energy)\n",
    "    if n == 0:\n",
    "        return []\n",
    "\n",
    "    views = event_to_views(event_rec)   # one dict per Reco trackster\n",
    "\n",
    "    idxs = list(range(n))\n",
    "    rng.shuffle(idxs)\n",
    "\n",
    "    groups, cur = [], 0\n",
    "    while cur < n:\n",
    "        gsize = min(rng.randint(1, max_group_size), n - cur)\n",
    "        groups.append(idxs[cur : cur + gsize])\n",
    "        cur += gsize\n",
    "\n",
    "    merged_out = []\n",
    "    for g in groups:\n",
    "        if len(g) == 1:\n",
    "            merged_out.append(views[g[0]])\n",
    "        else:\n",
    "            merged = functools.reduce(lambda a, b: merge_views(a, b),\n",
    "                                      (views[i] for i in g))\n",
    "            merged_out.append(merged)\n",
    "    return merged_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27070c3-2935-4791-b591-531f3bc104cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "events:  92%|█████████▏| 919/1000 [00:56<00:04, 16.99it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "sim_to_reco_tables = []    \n",
    "reco_to_sim_tables = []    \n",
    "all_merged_reco    = []    \n",
    "\n",
    "rng = random.Random(123)\n",
    "\n",
    "Nevents = 1000     # or any shorter “range(N)”\n",
    "for ev in tqdm(range(Nevents), desc=\"events\"):\n",
    "    reco_ev = ticlTrackstersCLUE3D[ev]     \n",
    "    sim_ev  = simTrackstersCP[ev]          \n",
    "\n",
    "    merged_reco = random_group_merging(reco_ev, rng=rng)\n",
    "\n",
    "    all_merged_reco.append(merged_reco)\n",
    "\n",
    "    if len(sim_ev.raw_energy) == 0:\n",
    "        sim_to_reco_tables.append([])\n",
    "        reco_to_sim_tables.append([])\n",
    "        continue\n",
    "\n",
    "    sim_to_reco_tables.append(\n",
    "        compute_sim_to_reco_scores(sim_ev, merged_reco, best_only=True)\n",
    "    )\n",
    "    reco_to_sim_tables.append(\n",
    "        compute_reco_to_sim_scores(sim_ev, merged_reco, best_only=False)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1436c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_efficiency = aggregate_for_efficiency(\n",
    "    simTrackstersCP, sim_to_reco_tables, score_threshold=0.6\n",
    ")\n",
    "data_merged = aggregate_for_merge(\n",
    "    all_merged_reco, reco_to_sim_tables, score_threshold=0.6\n",
    ")\n",
    "data_fake = aggregate_for_fake(\n",
    "    all_merged_reco, reco_to_sim_tables, score_threshold=0.6\n",
    ")\n",
    "\n",
    "plot_all_metrics(\n",
    "    data_efficiency,\n",
    "    data_merged,\n",
    "    data_fake,\n",
    "    out_file=\"ticl_metrics_grid.pdf\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153dfa6-1866-4c9e-9c1f-c15c4866bf01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
